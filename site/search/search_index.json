{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"Index/","title":"\ud83c\udfe1 Property Intelligence Pipeline \u2014 Documentation","text":"<p>Welcome to the official documentation for the Property Intelligence Pipeline. This system is a production-grade real estate data extraction, analytics, and prediction pipeline built with resilience, scalability, and observability at its core.  </p>"},{"location":"Index/#table-of-contents","title":"\ud83d\udcd6 Table of Contents","text":"<ul> <li>System Architecture</li> <li>Core Components</li> <li>Machine Learning Pipeline</li> <li>API Reference</li> <li>Observability</li> <li>Deployment Guide</li> <li>Operations &amp; Runbook</li> <li>Roadmap</li> </ul>"},{"location":"Index/#why-this-project-matters","title":"\ud83d\ude80 Why This Project Matters","text":"<p>Real estate data is fragmented, inconsistent, and often unstructured. This pipeline turns that chaos into clean, structured, and actionable intelligence, complete with:  </p> <ul> <li>Automated data ingestion from property sites  </li> <li>High-quality structured storage (PostgreSQL + ORM)  </li> <li>Analytics &amp; insights (affordable/expensive listings, trends)  </li> <li>Predictive intelligence via a trained ML model  </li> <li>Production-grade observability (Prometheus + Grafana)  </li> <li>Fully containerized &amp; CI/CD ready </li> </ul> <p>This documentation explains every layer in detail, from scraping to predictions to monitoring.  </p>"},{"location":"api_reference/","title":"\ud83d\udce1 API Reference","text":"<p>The API is powered by FastAPI and fully documented via OpenAPI/Swagger.</p>"},{"location":"api_reference/#authentication","title":"\ud83d\udd12 Authentication","text":"<ul> <li>All endpoints require an <code>X-Token</code> header.</li> <li>Value must match <code>API_TOKEN</code> environment variable.</li> </ul>"},{"location":"api_reference/#properties","title":"\ud83c\udfe1 Properties","text":""},{"location":"api_reference/#get-properties","title":"GET <code>/properties/</code>","text":"<ul> <li>Returns list of all properties.</li> </ul>"},{"location":"api_reference/#get-propertiesidfloor-plans","title":"GET <code>/properties/{id}/floor-plans</code>","text":"<ul> <li>Returns floor plans for a given property.</li> <li>404 if not found.</li> </ul>"},{"location":"api_reference/#_1","title":"API Reference","text":""},{"location":"api_reference/#analytics","title":"\ud83d\udcca Analytics","text":""},{"location":"api_reference/#get-analyticstopxmost-affordable","title":"GET <code>/analytics/top/{x}/most-affordable</code>","text":"<ul> <li>Returns top <code>x</code> cheapest floor plans.</li> </ul>"},{"location":"api_reference/#get-analyticstopxmost-expensive","title":"GET <code>/analytics/top/{x}/most-expensive</code>","text":"<ul> <li>Returns top <code>x</code> most expensive floor plans. </li> </ul>"},{"location":"api_reference/#get-analyticsthis-weeks-listings","title":"GET <code>/analytics/this-weeks-listings</code>","text":"<ul> <li>Listings added in last 7 days.</li> </ul>"},{"location":"api_reference/#get-analyticssearch","title":"GET <code>/analytics/search</code>","text":"<ul> <li>Search by filters:</li> <li><code>city</code></li> <li><code>min_bedrooms</code></li> <li><code>max_base_rent</code></li> <li><code>year_built</code></li> </ul>"},{"location":"api_reference/#predictions","title":"\ud83d\udd2e Predictions","text":""},{"location":"api_reference/#get-predictrent","title":"GET <code>/predict/rent</code>","text":"<ul> <li>Input: bedrooms, bathrooms, sqft, state, year_built</li> <li>Output: predicted rent price.</li> </ul> <p>Example: ```bash curl -X GET \"http://localhost:8000/predict/rent?bedrooms=2&amp;bathrooms=1&amp;sqft=800&amp;state=CA&amp;year_built=2010\" \\   -H \"X-Token: your_api_token\"</p>"},{"location":"architecture/","title":"\ud83c\udfd7\ufe0f System Architecture","text":"<p>The Property Intelligence Pipeline is based on a Producer\u2013Consumer model, augmented with a Machine Learning pipeline and full observability stack.</p>"},{"location":"architecture/#end-to-end-data-flow","title":"\ud83d\udd04 End-to-End Data Flow","text":"<ol> <li>Producer discovers property URLs and enqueues them into AWS SQS.  </li> <li>Consumer polls SQS, scrapes details, validates data, and persists into PostgreSQL.  </li> <li>FastAPI exposes the data, analytics, and ML predictions.  </li> <li>Prometheus &amp; Grafana provide full observability.  </li> <li>ML Pipeline trains rent prediction models using historical data.  </li> </ol>"},{"location":"architecture/#diagrams","title":"\ud83d\udcca Diagrams","text":""},{"location":"architecture/#high-level-overview","title":"High-Level Overview","text":""},{"location":"architecture/#system-flow","title":"System Flow","text":""},{"location":"architecture/#ml-pipeline","title":"ML Pipeline","text":""},{"location":"architecture/#fastapi-flow","title":"FastAPI flow","text":""},{"location":"components/","title":"\ud83e\udde9 Core Components","text":"<p>This section breaks down each component of the pipeline.</p>"},{"location":"components/#configpy","title":"\u2699\ufe0f config.py","text":"<ul> <li>Centralized configuration for all parameters:</li> <li><code>PROMETHEUS_PORT</code>, <code>SCRAPER_CONFIG</code>, <code>USER_AGENTS</code>, <code>ML_CONFIG</code>.</li> <li>Prevents magic numbers and centralizes system settings.</li> </ul>"},{"location":"components/#producerpy","title":"\ud83d\ude80 producer.py","text":"<ul> <li>Discovers property listing URLs.</li> <li>Enqueues each URL into AWS SQS.</li> <li>Key Features:</li> <li>Async Playwright scraping</li> <li>Pagination handling</li> <li>URL filtering/limiting</li> <li>Concurrent enqueueing</li> </ul>"},{"location":"components/#consumerpy","title":"\ud83d\udce6 consumer.py","text":"<ul> <li>Polls SQS for messages.</li> <li>Scrapes property details.</li> <li>Persists data into PostgreSQL.</li> <li>Features:</li> <li>Long-lived Playwright browser context</li> <li>Async scraping with concurrency limits</li> <li>Data validation</li> <li>Upsert persistence logic</li> <li>Prometheus metrics</li> <li>Graceful shutdown (SIGINT, SIGTERM)</li> </ul>"},{"location":"components/#scraperpy","title":"\ud83d\udd77\ufe0f scraper.py","text":"<ul> <li>Encapsulates Playwright scraping logic.</li> <li>Features:</li> <li>Async context manager for browser lifecycle</li> <li>User-agent rotation</li> <li>Resilient retry logic</li> <li>Single property page scraping with validation</li> <li>Defensive scraping (closing pages after use)</li> </ul>"},{"location":"components/#data_extractorpy","title":"\ud83d\udcdd data_extractor.py","text":"<ul> <li>Handles parsing and cleaning of data.</li> <li>Fault-tolerant with helper methods (<code>safe_inner_text</code>, <code>safe_get_attribute</code>).</li> <li>Extracts multi-floor plans, normalizes data.</li> </ul>"},{"location":"components/#database-layer","title":"\ud83d\udcbe Database Layer","text":""},{"location":"components/#dbmodelspy","title":"dbmodels.py","text":"<ul> <li>SQLModel ORM definitions:</li> <li><code>Property</code> table (listing info, metadata)</li> <li><code>Pricing_and_floor_plans</code> table (unit-level details)</li> </ul>"},{"location":"components/#db_opspy","title":"db_ops.py","text":"<ul> <li>Handles database sessions, inserts, updates.</li> <li>Features:</li> <li>Async PostgreSQL engine</li> <li>Upsert logic with rollback on error</li> <li>Numeric parsing &amp; type conversion</li> <li>Timezone-aware timestamps</li> </ul>"},{"location":"components/#fastapi-layer","title":"\ud83d\udcc8 FastAPI Layer","text":"<ul> <li>Routers: <code>/properties</code>, <code>/analytics</code>, <code>/predict</code></li> <li>Security: token-based authentication</li> <li>Features:</li> <li>Pydantic models for response validation</li> <li>Analytics queries</li> <li>Real-time ML predictions</li> </ul>"},{"location":"deployment/","title":"\ud83d\ude80 Deployment Guide","text":""},{"location":"deployment/#docker-setup","title":"\ud83d\udc33 Docker Setup","text":"<ul> <li>Each service is containerized.</li> <li><code>docker-compose.yml</code> orchestrates:</li> <li>FastAPI</li> <li>PostgreSQL</li> <li>Prometheus</li> <li>Grafana</li> </ul>"},{"location":"deployment/#cicd-github-actions","title":"\ud83d\udcc2 CI/CD (GitHub Actions)","text":"<ul> <li>Workflow: <code>.github/workflows/deploy.yml</code></li> <li>On push to <code>master</code>:</li> <li>Install dependencies</li> <li>Run tests (pytest)</li> <li>Build Docker image</li> <li>Produces reproducible, tested builds.</li> </ul>"},{"location":"deployment/#aws-setup","title":"\u2601\ufe0f AWS Setup","text":"<ul> <li>SQS Queue required.</li> <li>Provide credentials via ENV variables:</li> <li><code>AWS_ACCESS_KEY_ID</code></li> <li><code>AWS_SECRET_ACCESS_KEY</code></li> <li><code>SQS_QUEUE_URL</code></li> </ul>"},{"location":"deployment/#local-development","title":"\ud83d\udee0\ufe0f Local Development","text":"<pre><code>docker-compose up --build\n</code></pre> <p>FastAPI at http://localhost:8000</p> <p>Grafana at http://localhost:3000</p>"},{"location":"ml_pipeline/","title":"\ud83e\udde0 Machine Learning Pipeline","text":"<p>The pipeline includes a rent prediction model built with scikit-learn.  </p>"},{"location":"ml_pipeline/#ml_configspy","title":"\u2699\ufe0f ml_configs.py","text":"<ul> <li>Centralized ML configuration (model paths, hyperparameters).</li> </ul>"},{"location":"ml_pipeline/#data_loaderpy","title":"\ud83d\udce5 data_loader.py","text":"<ul> <li>Fetches structured property + floor plan data from PostgreSQL.</li> <li>Cleans and prepares features:</li> <li>Bedrooms, bathrooms, sqft, reviews, year built, etc.</li> </ul>"},{"location":"ml_pipeline/#preprocessorpy","title":"\u2728 preprocessor.py","text":"<ul> <li>Defines transformation pipeline:</li> <li>StandardScaler for numeric features</li> <li>OneHotEncoder for categorical features</li> <li>Built using <code>ColumnTransformer</code>.</li> </ul>"},{"location":"ml_pipeline/#trainerpy","title":"\ud83c\udfcb\ufe0f trainer.py","text":"<ul> <li>Splits data into train/test.</li> <li>Trains Linear Regression model.</li> <li>Evaluates using MSE and R\u00b2.</li> <li>Saves pipeline (<code>preprocessor + model</code>) into <code>.pkl</code>.</li> </ul>"},{"location":"ml_pipeline/#mainpy","title":"\ud83c\udfb6 main.py","text":"<ul> <li>Orchestrates ML pipeline:</li> <li>Load \u2192 preprocess \u2192 train \u2192 evaluate \u2192 save model</li> <li>Provides error handling.</li> <li>Designed for scheduled retraining.</li> </ul>"},{"location":"ml_pipeline/#prediction-flow","title":"\ud83d\udd2e Prediction Flow","text":"<ul> <li>Model is loaded at FastAPI startup.</li> <li>API endpoint <code>/predict/rent</code> uses the trained pipeline.</li> <li>Returns rent price predictions in real-time.</li> </ul>"},{"location":"observability/","title":"\ud83d\udcca Observability &amp; Monitoring","text":"<p>The pipeline has full observability with Prometheus + Grafana.</p>"},{"location":"observability/#custom-metrics","title":"\ud83d\udd11 Custom Metrics","text":"<p>Defined in <code>metrics.py</code>: - <code>SCRAPER_SUCCESS</code>, <code>SCRAPER_FAILURES</code> - <code>LISTINGS_SCRAPED</code> - <code>VALIDATION_SUCCESS</code>, <code>VALIDATION_FAILURES</code> - <code>DB_INSERT_FAILURES</code> - <code>CPU_USAGE</code>, <code>MEMORY_USAGE</code> - API request count &amp; latency</p>"},{"location":"observability/#prometheus-config","title":"\u2699\ufe0f Prometheus Config","text":"<ul> <li>Scrapes metrics from:</li> <li>FastAPI (<code>:8000/metrics</code>)</li> <li>Consumer service (<code>:8001/metrics</code>)</li> <li>Scrape interval: 15s</li> </ul>"},{"location":"observability/#grafana","title":"\ud83d\udcc8 Grafana","text":"<ul> <li>Pre-provisioned data source (Prometheus).</li> <li>Dashboards:</li> <li>Scraper health</li> <li>API latency</li> <li>DB inserts</li> <li>Resource usage</li> </ul>"},{"location":"observability/#alerts","title":"\ud83d\udea8 Alerts","text":"<p>Recommended alerts: - Scraper failures &gt; 5/min - DB insert failures spike - API latency &gt; 2s - CPU usage &gt; 80%</p>"},{"location":"operations/","title":"\ud83e\uddf0 Operations &amp; Runbook","text":""},{"location":"operations/#startup-checklist","title":"\u2705 Startup Checklist","text":"<ol> <li>Ensure AWS SQS is configured.</li> <li>Run <code>docker-compose up</code>.</li> <li>Verify:</li> <li>DB tables created</li> <li>ML model loaded</li> <li>Prometheus scraping metrics</li> </ol>"},{"location":"operations/#common-issues","title":"\u26a0\ufe0f Common Issues","text":"<ul> <li>SQS Connection Failure \u2192 Check credentials and queue URL.</li> <li>Scraper Timeout \u2192 Increase timeout/delay in <code>SCRAPER_CONFIG</code>.</li> <li>DB IntegrityError \u2192 Ensure schema matches ORM definitions.</li> <li>Model Not Loading \u2192 Verify correct <code>MODEL_PATH</code>.</li> </ul>"},{"location":"operations/#on-call-guide","title":"\ud83d\udee1\ufe0f On-Call Guide","text":"<ul> <li>First check Grafana dashboards.</li> <li>Look for spikes in <code>SCRAPER_FAILURES</code> or API latency.</li> <li>Validate Prometheus targets are healthy.</li> </ul>"},{"location":"operations/#recovery-procedures","title":"\ud83d\udd04 Recovery Procedures","text":"<ul> <li>Restart consumer if scraping fails continuously.</li> <li>Replay failed messages from SQS DLQ.</li> <li>For DB issues, rollback transaction &amp; re-run.</li> </ul>"},{"location":"roadmap/","title":"\ud83d\uddfa\ufe0f Roadmap","text":"<p>Planned future enhancements:</p> <ul> <li>Scalability</li> <li>Replace SQS with Kafka for high-volume ingestion</li> <li>Horizontal scaling of consumers</li> <li>Machine Learning</li> <li>MLflow for model tracking &amp; versioning</li> <li>Ensemble models for rent prediction</li> <li>Search</li> <li>ElasticSearch integration for full-text property search</li> <li>Data Quality</li> <li>Anomaly detection for fraudulent listings</li> <li>Deduplication across multiple sources</li> <li>Deployment</li> <li>Multi-region scraping deployment</li> <li>Kubernetes-based orchestration</li> </ul>"}]}